{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-03T03:53:22.011075Z","iopub.execute_input":"2024-10-03T03:53:22.011382Z","iopub.status.idle":"2024-10-03T03:53:23.067666Z","shell.execute_reply.started":"2024-10-03T03:53:22.011349Z","shell.execute_reply":"2024-10-03T03:53:23.066586Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"pip uninstall transformers -y","metadata":{"execution":{"iopub.status.busy":"2024-10-03T03:53:57.051615Z","iopub.execute_input":"2024-10-03T03:53:57.052483Z","iopub.status.idle":"2024-10-03T03:54:02.478299Z","shell.execute_reply.started":"2024-10-03T03:53:57.052440Z","shell.execute_reply":"2024-10-03T03:54:02.477123Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Found existing installation: transformers 4.44.2\nUninstalling transformers-4.44.2:\n  Successfully uninstalled transformers-4.44.2\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install -q git+https://github.com/huggingface/transformers.git qwen-vl-utils flash-attn optimum auto-gptq bitsandbytes","metadata":{"execution":{"iopub.status.busy":"2024-10-03T03:54:11.065911Z","iopub.execute_input":"2024-10-03T03:54:11.066932Z","iopub.status.idle":"2024-10-03T03:55:31.058618Z","shell.execute_reply.started":"2024-10-03T03:54:11.066889Z","shell.execute_reply":"2024-10-03T03:55:31.057297Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Note: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import Qwen2VLForConditionalGeneration, AutoTokenizer, AutoProcessor\nfrom qwen_vl_utils import process_vision_info\nimport torch\n\nmodel = Qwen2VLForConditionalGeneration.from_pretrained(\n    \"Qwen/Qwen2-VL-2B-Instruct\",\n    trust_remote_code=True,\n    torch_dtype=torch.bfloat16).cuda().eval()\n","metadata":{"execution":{"iopub.status.busy":"2024-10-03T04:15:38.458206Z","iopub.execute_input":"2024-10-03T04:15:38.459252Z","iopub.status.idle":"2024-10-03T04:16:13.401269Z","shell.execute_reply.started":"2024-10-03T04:15:38.459184Z","shell.execute_reply":"2024-10-03T04:16:13.400388Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51af269b2952402c8b9818b01eaf99ec"}},"metadata":{}},{"name":"stderr","text":"Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/56.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba5e97b2ff4b4414b01effd6314c1951"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dda4dd6aa09a4307b19d31d3fbde990c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/3.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c1e85331b094d4fb32fd680a50bfeb8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/429M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d10e927c3d3c47c0945261498ba4dffe"}},"metadata":{}},{"name":"stderr","text":"`Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"156abfd0ba164241b19c668a473e6d57"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/272 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8021723230d946c7b733b3817538eb66"}},"metadata":{}}]},{"cell_type":"code","source":"processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-2B-Instruct\", trust_remote_code=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-03T04:16:23.435084Z","iopub.execute_input":"2024-10-03T04:16:23.436409Z","iopub.status.idle":"2024-10-03T04:16:27.321053Z","shell.execute_reply.started":"2024-10-03T04:16:23.436363Z","shell.execute_reply":"2024-10-03T04:16:27.320203Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/347 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8f092ef47da40df812a3c6f96298aa9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/4.19k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d94d6922d6ad42f891866bcae5e4cab7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2b1b660d40c412194c1ab6f5541205b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c7b3c17e532457eaa3137dde35a78ec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56d0fd298bd5461eb924359d1f1f1192"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"chat_template.json:   0%|          | 0.00/1.05k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35cbecd9d1a846b49f051e084133a084"}},"metadata":{}}]},{"cell_type":"code","source":"from pdf2image import convert_from_path\n\nimages = convert_from_path(\"./docs/attention.pdf\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images[7]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_index = results[0][\"page_num\"] - 1\nimage_index","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"query = \"What's the BLEU score for the transformer base model?\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"messages = [\n    {\n        \"role\": \"user\",\n        \"content\": [\n            {\n                \"type\": \"image\",\n                \"image\": images[image_index],\n            },\n            {\"type\": \"text\", \"text\": query},\n        ],\n    }\n]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text = processor.apply_chat_template(\n    messages, tokenize=False, add_generation_prompt=True\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_inputs, video_inputs = process_vision_info(messages)\ninputs = processor(\n    text=[text],\n    images=image_inputs,\n    videos=video_inputs,\n    padding=True,\n    return_tensors=\"pt\",\n)\ninputs = inputs.to(\"cuda\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generated_ids = model.generate(**inputs, max_new_tokens=50)\ngenerated_ids_trimmed = [\n    out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n]\noutput_text = processor.batch_decode(\n    generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(output_text)","metadata":{},"execution_count":null,"outputs":[]}]}